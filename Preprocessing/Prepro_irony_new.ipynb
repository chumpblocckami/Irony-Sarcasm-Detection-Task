{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer \n",
    "import torch\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from torch import nn\n",
    "import os\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from ark_tweet_pos import CMUTweetTagger\n",
    "import shlex\n",
    "run_tagger_cmd = \"java -XX:ParallelGCThreads=10 -Xmx500m -jar ark_tweet_pos/ark-tweet-nlp-0.3.2.jar\"\n",
    "import FeaturesText\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\",output_hidden_states=True)\n",
    "tokenizer_bert = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", normalization=True, truncation = True, max_lenth = 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/final_training_semeval.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pos and embeddings layers from bert-tweet (training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.replace(r'#([^\\s:]+)', '')\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_file = FeaturesText.preprocessing_text(data,remove_hashtags=True, remove_mentions=True, lowercase=True, arktweet_pos=True)\n",
    "start = time.time()\n",
    "train_txt = txt_file.get_clean_df()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = train_txt[train_txt.astype(str).pos != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_train_txt = FeaturesText.ExtractFeatures(train_txt, 'other', svd_transform=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, punctuation_features, emoji_features, \\\n",
    "onomato_features, initialism_features,\\\n",
    "polarity_subj_features = final_train_txt.get_all_features_train(ngram_range=(1,1), dimensionality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = {'pos': pos,'polarity':polarity_subj_features, 'emoji': emoji_features,'punc': punctuation_features, \n",
    "                                'onom': onomato_features, 'init': initialism_features, 'label': np.asarray(train_txt.label.tolist())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/features_training_sarc_twitter_new_approach_semeval.p', 'wb') as fp:\n",
    "    pickle.dump(train_features, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['list'] = data.text.apply(lambda x: x.split(' '))\n",
    "data['len_list'] = data.list.str.len()\n",
    "data = data[data.len_list > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ln = np.array([len(ast.literal_eval(i)) for i in data.pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# plt.hist(ln)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=30)\n",
    "tokenizer.fit_on_texts(train_txt['pos'].astype(str))\n",
    "sequences_pos = tokenizer.texts_to_sequences(train_txt['pos'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pos = pad_sequences(sequences_pos, maxlen=30, padding='post', truncating='post')\n",
    "pos_tensor = torch.unsqueeze(torch.tensor(data_pos, dtype=torch.float),1)\n",
    "torch.save(pos_tensor.float().clone(), '../data/new_approach/train/irony/pos_tensor_semeval.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textattack.augmentation import WordNetAugmenter\n",
    "from textattack.augmentation import EmbeddingAugmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmenter = WordNetAugmenter(pct_words_to_swap=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "text_aug = []\n",
    "for i in tqdm(range(len(data))): \n",
    "        if i >= 5000 and data.label.iloc[i] == 1:\n",
    "            aug = augmenter.augment(data.text.iloc[i])\n",
    "            label = data.label.iloc[i]\n",
    "            text_aug.append(' '.join(map(str, aug)))\n",
    "            label_list.append(label)\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented = pd.DataFrame(text_aug, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented['label'] = label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt = pd.concat([data, augmented]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt.to_csv('../data/new_approach/augmented_irony_training.csv')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Sentence embedding extraction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_txt.drop('index', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [torch.tensor([tokenizer_bert.encode(i, truncation=True, padding=True, max_length=60)]) for i in train_txt.text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentence = torch.zeros((len(input_ids),1,768))\n",
    "y_target = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(input_ids))):\n",
    "        \n",
    "        features = bertweet(input_ids[i]) #extract sentence embedding 1 x 768 for each document\n",
    "        batch_sentence[i, :] = features[1]\n",
    "        y_target.append(train_txt.label.iloc[i])\n",
    "        \n",
    "ground_truth = torch.tensor(y_target, dtype = torch.float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_sentence.float().clone(), '../data/new_approach/train/irony/sentence_layer.pt')\n",
    "torch.save(ground_truth.float().clone(), '../data/new_approach/train/irony/y_train_sentence.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_target = []\n",
    "# y_val = []\n",
    "# batch_initial = torch.zeros((len(input_ids)-5000,4,1,768))\n",
    "# batch_middle = torch.zeros((len(input_ids)-5000,4,1,768))\n",
    "# batch_last = torch.zeros((len(input_ids)-5000,4,1,768))\n",
    "\n",
    "# batch_initial_val = torch.zeros((5000,4,1,768))\n",
    "# batch_middle_val = torch.zeros((5000,4,1,768))\n",
    "# batch_last_val = torch.zeros((5000,4,1,768))\n",
    "# index = 0\n",
    "    \n",
    "# with torch.no_grad():\n",
    "    \n",
    "#     for i in tqdm(range(len(input_ids))):\n",
    "        \n",
    "#         features = bertweet(input_ids[i]) #extract sentence embedding 1 x 768 for each document\n",
    "        \n",
    "#         sentence_emb_1 = torch.mean(features[2][1], dim=1).view(1, -1) #layer 1 \n",
    "#         sentence_emb_2 = torch.mean(features[2][2], dim=1).view(1, -1)\n",
    "#         sentence_emb_3 = torch.mean(features[2][3], dim=1).view(1, -1)\n",
    "#         sentence_emb_4 = torch.mean(features[2][4], dim=1).view(1, -1)\n",
    "#         sentence_emb_5 = torch.mean(features[2][5], dim=1).view(1, -1)\n",
    "#         sentence_emb_6 = torch.mean(features[2][6], dim=1).view(1, -1)\n",
    "#         sentence_emb_7 = torch.mean(features[2][7], dim=1).view(1, -1)\n",
    "#         sentence_emb_8 = torch.mean(features[2][8], dim=1).view(1, -1)\n",
    "#         sentence_emb_9 = torch.mean(features[2][9], dim=1).view(1, -1)\n",
    "#         sentence_emb_10 = torch.mean(features[2][10], dim=1).view(1, -1)\n",
    "#         sentence_emb_11 = torch.mean(features[2][11], dim=1).view(1, -1)\n",
    "#         sentence_emb_12 = torch.mean(features[2][12], dim=1).view(1, -1) #layer 12\n",
    "\n",
    "#         sub_layers_initial = torch.stack((sentence_emb_1, sentence_emb_2, sentence_emb_3, sentence_emb_4), dim= 1).reshape(1,4,1,768)  #add batch dimension\n",
    "#         sub_layers_middle = torch.stack((sentence_emb_5, sentence_emb_6, sentence_emb_7, sentence_emb_8), dim= 1).reshape(1,4,1,768)\n",
    "#         sub_layers_last = torch.stack((sentence_emb_9, sentence_emb_10, sentence_emb_11, sentence_emb_12), dim= 1).reshape(1,4,1,768)\n",
    "#         if i < 5000:\n",
    "            \n",
    "#             batch_initial_val[i,:] = sub_layers_initial\n",
    "#             batch_middle_val[i,:] = sub_layers_middle\n",
    "#             batch_last_val[i,:] = sub_layers_last\n",
    "#             y_val.append(train_txt.label.iloc[i])\n",
    "#         else:\n",
    "#             batch_initial[index,:] = sub_layers_initial\n",
    "#             batch_middle[index,:] = sub_layers_middle\n",
    "#             batch_last[index,:] = sub_layers_last\n",
    "        \n",
    "#             y_target.append(train_txt.label.iloc[i])\n",
    "#             index += 1\n",
    "            \n",
    "# ground_val = torch.tensor(y_val, dtype = torch.float)             \n",
    "# ground_truth = torch.tensor(y_target, dtype = torch.float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = []\n",
    "batch_initial = torch.zeros((len(input_ids),4,1,768))\n",
    "batch_middle = torch.zeros((len(input_ids),4,1,768))\n",
    "batch_last = torch.zeros((len(input_ids),4,1,768))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i in tqdm(range(len(input_ids))):\n",
    "        \n",
    "        features = bertweet(input_ids[i]) #extract sentence embedding 1 x 768 for each document\n",
    "        \n",
    "        sentence_emb_1 = torch.mean(features[2][1], dim=1).view(1, -1) #layer 1 \n",
    "        sentence_emb_2 = torch.mean(features[2][2], dim=1).view(1, -1)\n",
    "        sentence_emb_3 = torch.mean(features[2][3], dim=1).view(1, -1)\n",
    "        sentence_emb_4 = torch.mean(features[2][4], dim=1).view(1, -1)\n",
    "        sentence_emb_5 = torch.mean(features[2][5], dim=1).view(1, -1)\n",
    "        sentence_emb_6 = torch.mean(features[2][6], dim=1).view(1, -1)\n",
    "        sentence_emb_7 = torch.mean(features[2][7], dim=1).view(1, -1)\n",
    "        sentence_emb_8 = torch.mean(features[2][8], dim=1).view(1, -1)\n",
    "        sentence_emb_9 = torch.mean(features[2][9], dim=1).view(1, -1)\n",
    "        sentence_emb_10 = torch.mean(features[2][10], dim=1).view(1, -1)\n",
    "        sentence_emb_11 = torch.mean(features[2][11], dim=1).view(1, -1)\n",
    "        sentence_emb_12 = torch.mean(features[2][12], dim=1).view(1, -1) #layer 12\n",
    "\n",
    "        sub_layers_initial = torch.stack((sentence_emb_1, sentence_emb_2, sentence_emb_3, sentence_emb_4), dim= 1).reshape(1,4,1,768)  #add batch dimension\n",
    "        sub_layers_middle = torch.stack((sentence_emb_5, sentence_emb_6, sentence_emb_7, sentence_emb_8), dim= 1).reshape(1,4,1,768)\n",
    "        sub_layers_last = torch.stack((sentence_emb_9, sentence_emb_10, sentence_emb_11, sentence_emb_12), dim= 1).reshape(1,4,1,768)\n",
    "              \n",
    "        batch_initial[i,:] = sub_layers_initial\n",
    "        batch_middle[i,:] = sub_layers_middle\n",
    "        batch_last[i,:] = sub_layers_last\n",
    "        \n",
    "        y_target.append(train_txt.label.iloc[i])\n",
    "\n",
    "ground_truth = torch.tensor(y_target, dtype = torch.float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_initial.float().clone(), '../data/new_approach/train/irony/init_layer_semtask.pt')\n",
    "torch.save(batch_middle.float().clone(), '../data/new_approach/train/irony/middle_layer_semtask.pt')\n",
    "torch.save(batch_last.float().clone(), '../data/new_approach/train/irony/last_layer_semtask.pt')\n",
    "torch.save(ground_truth.float().clone(), '../data/new_approach/train/irony/y_train_semtask.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_initial_val.float().clone(), '../data/new_approach/train/irony_validation/init_layer.pt')\n",
    "torch.save(batch_middle_val.float().clone(), '../data/new_approach/train/irony_validation/middle_layer.pt')\n",
    "torch.save(batch_last_val.float().clone(), '../data/new_approach/train/irony_validation/last_layer.pt')\n",
    "torch.save(ground_val.float().clone(), '../data/new_approach/train/irony_validation/y_train.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pos and embeddings layers from bert-tweet (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = pd.read_csv('../data/SemEval2018-Task3/datasets/goldtest_TaskA/SemEval2018-T3_gold_test_taskA_emoji.txt', sep='\\t')\n",
    "sem.rename({'Tweet text': 'text', 'Label' : 'label'}, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_txt_file_sem = FeaturesText.preprocessing_text(sem,remove_hashtags=True, remove_mentions=True, lowercase=True, arktweet_pos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_txt_se = test_txt_file_sem.get_clean_df()\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_pos = tokenizer.texts_to_sequences(test_txt_ril['pos'].astype(str))\n",
    "data_pos = pad_sequences(sequences_pos, maxlen=30, padding='post', truncating='post')\n",
    "pos_tensor = torch.unsqueeze(torch.tensor(data_pos, dtype=torch.float),1)\n",
    "torch.save(pos_tensor.float().clone(), '../data/new_approach/test/irony/pos_tensor_sem.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [torch.tensor([tokenizer_bert.encode(i)]) for i in test_txt_se.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sentence = torch.zeros((len(input_ids),1,768))\n",
    "y_target = []\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(input_ids))):\n",
    "        \n",
    "        features = bertweet(input_ids[i]) #extract sentence embedding 1 x 768 for each document\n",
    "        batch_sentence[i, :] = features[1]\n",
    "        y_target.append(train_txt.label.iloc[i])\n",
    "        \n",
    "ground_truth = torch.tensor(y_target, dtype = torch.float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_sentence.float().clone(), '../data/new_approach/test/irony/sentence_layer_sem.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = []\n",
    "batch_initial = torch.zeros((len(input_ids),4,1,768))\n",
    "batch_middle = torch.zeros((len(input_ids),4,1,768))\n",
    "batch_last = torch.zeros((len(input_ids),4,1,768))\n",
    "    \n",
    "with torch.no_grad():\n",
    "    \n",
    "    for i in tqdm(range(len(input_ids))):\n",
    "        \n",
    "        features = bertweet(input_ids[i]) #extract sentence embedding 1 x 768 for each document\n",
    "        \n",
    "        sentence_emb_1 = torch.mean(features[2][1], dim=1).view(1, -1) #layer 1 \n",
    "        sentence_emb_2 = torch.mean(features[2][2], dim=1).view(1, -1)\n",
    "        sentence_emb_3 = torch.mean(features[2][3], dim=1).view(1, -1)\n",
    "        sentence_emb_4 = torch.mean(features[2][4], dim=1).view(1, -1)\n",
    "        sentence_emb_5 = torch.mean(features[2][5], dim=1).view(1, -1)\n",
    "        sentence_emb_6 = torch.mean(features[2][6], dim=1).view(1, -1)\n",
    "        sentence_emb_7 = torch.mean(features[2][7], dim=1).view(1, -1)\n",
    "        sentence_emb_8 = torch.mean(features[2][8], dim=1).view(1, -1)\n",
    "        sentence_emb_9 = torch.mean(features[2][9], dim=1).view(1, -1)\n",
    "        sentence_emb_10 = torch.mean(features[2][10], dim=1).view(1, -1)\n",
    "        sentence_emb_11 = torch.mean(features[2][11], dim=1).view(1, -1)\n",
    "        sentence_emb_12 = torch.mean(features[2][12], dim=1).view(1, -1) #layer 12\n",
    "\n",
    "        sub_layers_initial = torch.stack((sentence_emb_1, sentence_emb_2, sentence_emb_3, sentence_emb_4), dim= 1).reshape(1,4,1,768)  #add batch dimension\n",
    "        sub_layers_middle = torch.stack((sentence_emb_5, sentence_emb_6, sentence_emb_7, sentence_emb_8), dim= 1).reshape(1,4,1,768)\n",
    "        sub_layers_last = torch.stack((sentence_emb_9, sentence_emb_10, sentence_emb_11, sentence_emb_12), dim= 1).reshape(1,4,1,768)\n",
    "              \n",
    "        batch_initial[i,:] = sub_layers_initial\n",
    "        batch_middle[i,:] = sub_layers_middle\n",
    "        batch_last[i,:] = sub_layers_last\n",
    "        \n",
    "        y_target.append(test_txt_se.label.iloc[i])\n",
    "\n",
    "ground_truth = torch.tensor(y_target, dtype = torch.float)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(batch_initial.float().clone(), '../data/new_approach/test/irony/init_layer_sem.pt')\n",
    "torch.save(batch_middle.float().clone(), '../data/new_approach/test/irony/middle_layer_sem.pt')\n",
    "torch.save(batch_last.float().clone(), '../data/new_approach/test/irony/last_layer_sem.pt')\n",
    "torch.save(ground_truth.float().clone(), '../data/new_approach/test/irony/y_sem.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
