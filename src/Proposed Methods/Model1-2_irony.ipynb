{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer \n",
    "import torch\n",
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from torch import nn\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import classification_report\n",
    "from Attention_Augmented_Conv2d.attention_augmented_conv import AugmentedConv\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "from ark_tweet_pos import CMUTweetTagger\n",
    "import shlex\n",
    "run_tagger_cmd = \"java -XX:ParallelGCThreads=10 -Xmx500m -jar ark_tweet_pos/ark-tweet-nlp-0.3.2.jar\"\n",
    "import FeaturesText\n",
    "import wandb\n",
    "wandb.login()\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch_lr_finder import LRFinder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\" Applies attention mechanism on the `context` using the `query`.\n",
    "\n",
    "    **Thank you** to IBM for their initial implementation of :class:`Attention`. Here is\n",
    "    their `License\n",
    "    <https://github.com/IBM/pytorch-seq2seq/blob/master/LICENSE>`__.\n",
    "\n",
    "    Args:\n",
    "        dimensions (int): Dimensionality of the query and context.\n",
    "        attention_type (str, optional): How to compute the attention score:\n",
    "\n",
    "            * dot: :math:`score(H_j,q) = H_j^T q`\n",
    "            * general: :math:`score(H_j, q) = H_j^T W_a q`\n",
    "\n",
    "    Example:\n",
    "\n",
    "         >>> attention = Attention(256)\n",
    "         >>> query = torch.randn(5, 1, 256)\n",
    "         >>> context = torch.randn(5, 5, 256)\n",
    "         >>> output, weights = attention(query, context)\n",
    "         >>> output.size()\n",
    "         torch.Size([5, 1, 256])\n",
    "         >>> weights.size()\n",
    "         torch.Size([5, 1, 5])\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dimensions, attention_type='general'):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        if attention_type not in ['dot', 'general']:\n",
    "            raise ValueError('Invalid attention type selected.')\n",
    "\n",
    "        self.attention_type = attention_type\n",
    "        if self.attention_type == 'general':\n",
    "            self.linear_in = nn.Linear(dimensions, dimensions, bias=False)\n",
    "\n",
    "        self.linear_out = nn.Linear(dimensions * 2, dimensions, bias=False)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self, query, context):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            query (:class:`torch.FloatTensor` [batch size, output length, dimensions]): Sequence of\n",
    "                queries to query the context.\n",
    "            context (:class:`torch.FloatTensor` [batch size, query length, dimensions]): Data\n",
    "                overwhich to apply the attention mechanism.\n",
    "\n",
    "        Returns:\n",
    "            :class:`tuple` with `output` and `weights`:\n",
    "            * **output** (:class:`torch.LongTensor` [batch size, output length, dimensions]):\n",
    "              Tensor containing the attended features.\n",
    "            * **weights** (:class:`torch.FloatTensor` [batch size, output length, query length]):\n",
    "              Tensor containing attention weights.\n",
    "        \"\"\"\n",
    "        batch_size, output_len, dimensions = query.size()\n",
    "        query_len = context.size(1)\n",
    "\n",
    "        if self.attention_type == \"general\":\n",
    "            query = query.reshape(batch_size * output_len, dimensions)\n",
    "            query = self.linear_in(query)\n",
    "            query = query.reshape(batch_size, output_len, dimensions)\n",
    "\n",
    "        # TODO: Include mask on PADDING_INDEX?\n",
    "\n",
    "        # (batch_size, output_len, dimensions) * (batch_size, query_len, dimensions) ->\n",
    "        # (batch_size, output_len, query_len);\n",
    "        attention_scores = torch.bmm(query, context.transpose(1, 2).contiguous())\n",
    "\n",
    "        # Compute weights across every context sequence\n",
    "        attention_scores = attention_scores.view(batch_size * output_len, query_len)\n",
    "        attention_weights = self.softmax(attention_scores)\n",
    "        attention_weights = attention_weights.view(batch_size, output_len, query_len)\n",
    "\n",
    "        # (batch_size, output_len, query_len) * (batch_size, query_len, dimensions) ->\n",
    "        # (batch_size, output_len, dimensions)\n",
    "        mix = torch.bmm(attention_weights, context)\n",
    "\n",
    "        # concat -> (batch_size * output_len, 2*dimensions)\n",
    "        combined = torch.cat((mix, query), dim=2)\n",
    "        combined = combined.view(batch_size * output_len, 2 * dimensions)\n",
    "\n",
    "        # Apply linear_out on every 2nd dimension of concat\n",
    "        # output -> (batch_size, output_len, dimensions)\n",
    "        output = self.linear_out(combined).view(batch_size, output_len, dimensions)\n",
    "        output = self.dropout(self.tanh(output))\n",
    "\n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline_sentence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(baseline_sentence, self).__init__()\n",
    "        self.bgru = nn.GRU(2304, 1152, num_layers = 1, bidirectional = True, batch_first=True)\n",
    "        #self.bgru2 = nn.GRU(2304, 1152, num_layers = 1, bidirectional = True, batch_first=True)\n",
    "        self.attention1 = Attention(2304, 'dot')\n",
    "        self.max_pool = nn.MaxPool1d(9)\n",
    "        self.dense1 = nn.Linear(2304, 512)\n",
    "#         self.dense2 = nn.Linear(512,128)\n",
    "#         self.dense3 = nn.Linear(128,64)\n",
    "#         self.dense4 = nn.Linear(64,32)\n",
    "#         self.dense5 = nn.Linear(32, 16)\n",
    "        self.dense6 = nn.Linear(512,2)\n",
    "        self.drop = nn.Dropout(0.4)\n",
    "        \n",
    "    def forward(self, input1): \n",
    "        \n",
    "        gru, _ = self.bgru(input1)\n",
    "        gru = self.drop(gru)\n",
    "        attention1, _ = self.attention1(gru, input1)\n",
    "        #gru, _ = self.bgru2(attention1)\n",
    "        #gru = self.drop(gru)\n",
    "#         attention1, _ = self.attention1(gru, attention1)\n",
    "        \n",
    "        flattening = torch.squeeze(attention1, 1)\n",
    "        \n",
    "        dense = self.drop(F.relu(self.dense1(flattening)))\n",
    "#         dense = self.normalization2(dense)\n",
    "#         dense = self.drop(F.relu(self.dense2(dense)))\n",
    "#         dense = self.drop(F.relu(self.dense3(dense)))\n",
    "#         dense = self.drop(F.relu(self.dense4(dense)))\n",
    "#         dense = self.drop(F.relu(self.dense5(dense)))\n",
    "        \n",
    "        output = self.dense6(dense)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseline(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(baseline, self).__init__()\n",
    "        \n",
    "        self.conv2d = nn.Conv1d(4,3, kernel_size=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2d.weight, gain=5/3)\n",
    "        self.conv2d2 = nn.Conv1d(3,2, kernel_size=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2d2.weight, gain=5/3)\n",
    "        self.conv2d3 = nn.Conv1d(2,1, kernel_size=1)\n",
    "        torch.nn.init.xavier_uniform_(self.conv2d3.weight, gain=5/3)\n",
    "        self.bgru = nn.GRU(input_size=768, hidden_size=384, num_layers=1, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(768,attention_type = 'dot')\n",
    "        self.normalization = nn.BatchNorm1d(num_features=3)\n",
    "        self.normalization2 = nn.BatchNorm1d(num_features=2)\n",
    "        self.normalization3 = nn.BatchNorm1d(num_features=1)\n",
    "        self.drop = nn.Dropout(0.4)\n",
    "        self.drop2 = nn.Dropout(0.4)\n",
    "        self.drop3 = nn.Dropout(0.5)\n",
    "        self.dense7 = nn.Linear(768,256)\n",
    "        self.dense8 = nn.Linear(256,2)\n",
    "        \n",
    "    def forward(self, input1):\n",
    "        conv = self.drop3(F.relu(self.conv2d(input1)))\n",
    "        conv = self.normalization(conv)\n",
    "        attention_1, _ = self.attention(conv, input1) # N x 1 x 768\n",
    "        \n",
    "        conv = self.drop(F.relu(self.conv2d2(conv)))\n",
    "#         #conv = self.normalization2(conv)\n",
    "        attention_2, _ = self.attention(conv, attention_1)\n",
    "        \n",
    "        conv = self.drop(F.relu(self.conv2d3(conv)))\n",
    "#         #conv = self.normalization3(conv)\n",
    "        attention_3, _ = self.attention(conv, attention_2)\n",
    "        \n",
    "#         gru, _ = self.bgru(conv)\n",
    "#         #gru = self.normalization3(gru)\n",
    "#         attention, weights = self.attention(conv, gru)\n",
    "        flattening = self.drop(torch.squeeze(attention_3, 1))\n",
    "        dense = self.drop3(F.relu(self.dense7(flattening)))\n",
    "        output  = self.dense8(dense)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_undersampling(ground_truth, batch_last):\n",
    "    \n",
    "    idx_irony = (ground_truth == 1.0).nonzero().flatten()\n",
    "    idx_not_irony = (ground_truth == 0.0).nonzero().flatten()\n",
    "\n",
    "    x_irony = batch_last[idx_irony]\n",
    "    x_not_irony = batch_last[idx_not_irony]\n",
    "\n",
    "    y_irony = ground_truth[idx_irony]\n",
    "    y_not_irony = ground_truth[idx_not_irony]\n",
    "\n",
    "    perm = torch.randperm(y_not_irony.size()[0])\n",
    "    idx = perm[:y_irony.size()[0]]\n",
    "    samples_not_irony = x_not_irony[idx,:]\n",
    "    samples_y_not = y_not_irony[idx]\n",
    "\n",
    "    concat_x = torch.cat([x_irony, samples_not_irony], dim = 0)\n",
    "    concat_y = torch.cat([y_irony, samples_y_not], dim = 0)\n",
    "\n",
    "    X, y = shuffle(concat_x, concat_y)\n",
    "\n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramloader_sentence_train(batch_size, ground_truth,batch_last):\n",
    "    batch_last, ground_truth = custom_undersampling(ground_truth, batch_last)\n",
    "    n_batches_per_epoch = ground_truth.shape[0]//batch_size\n",
    "    for i in range(n_batches_per_epoch):\n",
    "        idx = list(range(ground_truth.shape[0])[batch_size*i:batch_size*(i+1)])\n",
    "        try:\n",
    "            y_target = ground_truth[idx]\n",
    "            batch_la = batch_last[idx, :]\n",
    "        except StopIteration:\n",
    "            batch_la = batch_last[:idx[-1]+1,:]\n",
    "            break    \n",
    "        yield batch_la, y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramloader_sentence(batch_size, ground_truth,batch_last):\n",
    "    n_batches_per_epoch = ground_truth.shape[0]//batch_size\n",
    "    for i in range(n_batches_per_epoch):\n",
    "        idx = list(range(ground_truth.shape[0])[batch_size*i:batch_size*(i+1)])\n",
    "        try:\n",
    "            y_target = ground_truth[idx]\n",
    "            batch_la = batch_last[idx, :]\n",
    "        except StopIteration:\n",
    "            batch_la = batch_last[:idx[-1]+1,:]\n",
    "            break    \n",
    "        yield batch_la, y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramloader_light_train(batch_size, ground_truth,batch_last):\n",
    "    batch_last, ground_truth = custom_undersampling(ground_truth, batch_last)\n",
    "    n_batches_per_epoch = ground_truth.shape[0]//batch_size\n",
    "    for i in range(n_batches_per_epoch):\n",
    "        idx = list(range(ground_truth.shape[0])[batch_size*i:batch_size*(i+1)])\n",
    "        try:\n",
    "            y_target = ground_truth[idx]\n",
    "            batch_la = batch_last[idx, :]\n",
    "        except StopIteration:\n",
    "            batch_la = batch_last[:idx[-1]+1,:]\n",
    "            break    \n",
    "        yield torch.squeeze(batch_la, 2),y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramloader_light(batch_size, ground_truth,batch_last):\n",
    "    n_batches_per_epoch = ground_truth.shape[0]//batch_size\n",
    "    for i in range(n_batches_per_epoch):\n",
    "        idx = list(range(ground_truth.shape[0])[batch_size*i:batch_size*(i+1)])\n",
    "        try:\n",
    "            y_target = ground_truth[idx]\n",
    "            batch_la = batch_last[idx, :]\n",
    "        except StopIteration:\n",
    "            batch_la = batch_last[:idx[-1]+1,:]\n",
    "            break    \n",
    "        yield torch.squeeze(batch_la, 2),y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_train = np.load('../Code/Deep_moji_feature/train/irony/sentence_emoji_train.npy')\n",
    "emoji_y = np.load('../Code/Deep_moji_feature/train/irony/y_emoji_train.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_train = torch.tensor(emoji_train, dtype=torch.float)\n",
    "emoji_y = torch.tensor(emoji_y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_train = torch.unsqueeze(emoji_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_initial = torch.load('../data/new_approach/train/sarcasm/init_layer.pt')\n",
    "# batch_middle = torch.load( '../data/new_approach/train/sarcasm/middle_layer.pt')\n",
    "batch_last = torch.load('../data/new_approach/train/irony/last_layer.pt')\n",
    "ground_truth = torch.load('../data/new_approach/train/irony/y_train.pt')\n",
    "# pos_tensor = torch.load('../data/new_approach/train/sarcasm/pos_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_val = torch.load('../data/new_approach/train/irony_validation/last_layer.pt')\n",
    "# ground_val = torch.load('../data/new_approach/train/irony_validation/y_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = baseline_sentence()\n",
    "mymodel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best lr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceEmb(torch.utils.data.Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.x = torch.squeeze(x_train,2)\n",
    "        self.y = y_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        ground_truth = torch.squeeze(self.y[idx]).long()\n",
    "        x = self.x[idx,:]\n",
    "    \n",
    "        return x, ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = SentenceEmb(X_train, y_train)\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "trainloader = torch.utils.data.DataLoader(training_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set = SentenceEmb(X_test, y_test)\n",
    "params = {'batch_size': 64,\n",
    "          'shuffle': True,\n",
    "          'num_workers': 0}\n",
    "testloader = torch.utils.data.DataLoader(validation_set, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 2e-5\n",
    "optimizer = torch.optim.AdamW(mymodel2.parameters(), lr=learning_rate, weight_decay=1e-8)\n",
    "lr_finder = LRFinder(mymodel2, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(trainloader, end_lr=1e-1, num_iter=500, step_mode=\"exp\")\n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.range_test(trainloader, val_loader=testloader, end_lr=1e-1, num_iter=1000, step_mode=\"exp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.load_state_dict(torch.load('../Code/model_pytorch/model_0.7834.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "transformer = PCA(0.95)\n",
    "transformer2 = PCA(344)\n",
    "transformer3 = PCA(344)\n",
    "transformer4 = PCA(344)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat1 = torch.unsqueeze(torch.tensor(transformer.fit_transform(torch.squeeze(batch_last[:, 0],1))), 1)\n",
    "feat2 = torch.unsqueeze(torch.tensor(transformer2.fit_transform(torch.squeeze(batch_last[:, 1],1))),1)\n",
    "feat3 = torch.unsqueeze(torch.tensor(transformer3.fit_transform(torch.squeeze(batch_last[:, 2],1))),1)\n",
    "feat4 = torch.unsqueeze(torch.tensor(transformer4.fit_transform(torch.squeeze(batch_last[:, 3],1))),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.unsqueeze(torch.cat((feat1,feat2,feat3,feat4), 1), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(emoji_train, emoji_y, stratify = emoji_y, test_size = 0.05, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-5\n",
    "optimizer = torch.optim.AdamW(mymodel.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_epoch = []\n",
    "loss_epoch = []\n",
    "accuracy_validation = []\n",
    "loss_validation = []\n",
    "best_val = 0\n",
    "for epoch in range(100):  # loop over the dataset multiple times\n",
    "    trainloader = ramloader_light_train(32, y_train, X_train)\n",
    "    accuracy_step = []\n",
    "    loss_step = []\n",
    "    for i, data in enumerate(trainloader):\n",
    "        \n",
    "        layer_high = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = mymodel(layer_high)\n",
    "        loss = criterion(outputs,  torch.squeeze(labels).long())\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "        \n",
    "        stepsize = int(y_train.shape[0]//32)\n",
    "        outputs = F.softmax(outputs)\n",
    "        _, predicted = torch.max(outputs,1)\n",
    "        y_actual = torch.squeeze(labels).cpu()\n",
    "        acc = accuracy_score(y_actual, predicted.cpu())\n",
    "        accuracy_step.append(accuracy_score(y_actual, predicted.cpu()))\n",
    "        loss_step.append(loss.item())\n",
    "        print('Epoch {}, Step {}/{}, Loss: {}, Accuracy: {}'.format(epoch,i,stepsize, loss.item(), acc), end = '\\r')\n",
    "        \n",
    "    mean_accuracy = np.mean(accuracy_step)\n",
    "    accuracy_epoch.append(mean_accuracy)\n",
    "    loss_epoch.append(np.mean(loss_step))\n",
    "    print(\"Accuracy epoch {}: {}\".format(epoch, mean_accuracy), end = '\\r')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        valoader = ramloader_light(32, y_test, X_test)\n",
    "        accuracy_step = []\n",
    "        loss_step = []\n",
    "        for i, data in enumerate(valoader):\n",
    "\n",
    "            layer_high = data[0].to(device)\n",
    "            labels = data[1].to(device)\n",
    "\n",
    "            outputs = mymodel(layer_high)\n",
    "            loss_val = criterion(outputs, torch.squeeze(labels).long())\n",
    "            outputs = F.softmax(outputs)\n",
    "            _, predicted = torch.max(outputs,1)\n",
    "            y_actual = torch.squeeze(labels).cpu()\n",
    "            accuracy_step.append(accuracy_score(y_actual, predicted.cpu()))\n",
    "            loss_step.append(loss_val.item())\n",
    "            \n",
    "        mean_accuracy = np.mean(accuracy_step)\n",
    "        accuracy_validation.append(mean_accuracy)\n",
    "        loss_validation.append(np.mean(loss_step))\n",
    "\n",
    "        if mean_accuracy > best_val:\n",
    "            best_val = mean_accuracy\n",
    "            torch.save(mymodel.state_dict(), '../Code/model_pytorch_irony/model_{}.pt'.format(best_val.round(4)))\n",
    "\n",
    "    scheduler.step(np.mean(loss_step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterat = list(range(len(accuracy_epoch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accur_tra = np.array(accuracy_epoch)\n",
    "accr_vali = np.array(accuracy_validation)\n",
    "loss_tra = np.array(loss_epoch)\n",
    "loss_val = np.array(loss_validation)\n",
    "iterat_n = np.array(iterat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accur_tra = np.load( '../Code/model_pytorch2_irony/accuracy_train.npy')\n",
    "accr_vali = np.load( '../Code/model_pytorch2_irony/accuracy_validation.npy')\n",
    "loss_tra = np.load( '../Code/model_pytorch2_irony/loss_train.npy')\n",
    "loss_val = np.load( '../Code/model_pytorch2_irony/loss_val.np.npy')\n",
    "iterat_n = np.load( '../Code/model_pytorch2_irony/epochs.np.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save( '../Code/model_pytorch_irony/accuracy_train', accur_tra)\n",
    "# np.save( '../Code/model_pytorch_irony/accuracy_validation', accr_vali)\n",
    "# np.save( '../Code/model_pytorch_irony/loss_train', loss_tra)\n",
    "# np.save( '../Code/model_pytorch_irony/loss_val.np', loss_val)\n",
    "# np.save( '../Code/model_pytorch_irony/epochs.np', iterat_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.grid(linestyle = 'dashed')\n",
    "plt.plot(iterat_n[:35], accur_tra[:35], c = 'green')\n",
    "plt.plot(iterat_n[:35], accr_vali[:35])\n",
    "plt.title('Accuracy Metric with respect to DeepMoji Features')\n",
    "plt.legend(['Train Set', 'Validation Set'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\thesis_latex\\img\\accuracy_model2_irony.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.grid(linestyle = 'dashed')\n",
    "plt.plot(iterat_n[:35], loss_tra[:35], c = 'green')\n",
    "plt.plot(iterat_n[:35], loss_val[:35])\n",
    "plt.title('Cross Entropy Loss with respect to DeepMoji Features')\n",
    "plt.legend(['Train Set', 'Validation Set'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\thesis_latex\\img\\loss_model2_irony.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pred(pred):\n",
    "    numpy_list = [i.numpy() for i in pred]\n",
    "    numpy_1vec = np.concatenate(numpy_list).ravel()\n",
    "    return numpy_1vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel.load_state_dict(torch.load('../Code/model_pytorch2_irony/model_0.9065.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_val = []\n",
    "    valoader = ramloader_light(9, y_test,X_test)\n",
    "    accuracy_step = []\n",
    "    loss_step = []\n",
    "    for i, data in enumerate(valoader):\n",
    "\n",
    "        layer_high = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "\n",
    "        outputs = mymodel(layer_high)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        outputs = mymodel(layer_high)\n",
    "        y_actual = torch.squeeze(labels).cpu()\n",
    "        acc = accuracy_score(y_actual, predicted.cpu())\n",
    "        prediction_val.append(predicted.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(normalize_pred(prediction_val), y_train[:40518]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(normalize_pred(prediction_val), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_last_sem= torch.load('../data/new_approach/test/irony/last_layer_sem.pt')\n",
    "ground_truth_sem = torch.load('../data/new_approach/test/irony/y_sem.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_train = np.load('../Code/Deep_moji_feature/test/sentence_emoji_sem.npy')\n",
    "emoji_y = np.load('../Code/Deep_moji_feature/test/y_emoji_sem.npy')\n",
    "emoji_train = torch.tensor(emoji_train, dtype=torch.float)\n",
    "emoji_y = torch.tensor(emoji_y, dtype=torch.long)\n",
    "emoji_train = torch.unsqueeze(emoji_train,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_train.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_val = []\n",
    "    valoader = ramloader_sentence(2,emoji_y,emoji_train)\n",
    "    accuracy_step = []\n",
    "    loss_step = []\n",
    "    for i, data in enumerate(valoader):\n",
    "\n",
    "        layer_high = data[0].to(device)\n",
    "        labels = data[1].to(device)\n",
    "\n",
    "        outputs = mymodel(layer_high)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        y_actual = torch.squeeze(labels).cpu()\n",
    "        acc = accuracy_score(y_actual, predicted.cpu())\n",
    "        prediction_val.append(predicted.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Semeval test, DeepMoji features')\n",
    "print(classification_report(normalize_pred(prediction_val),emoji_y.numpy())) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
