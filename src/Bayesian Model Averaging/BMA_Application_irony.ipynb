{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from tqdm import tqdm\n",
    "import bma_python\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/features_training_irony_twitter.p', 'rb') as handle:\n",
    "    train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = train['bert_embed']\n",
    "\n",
    "X_train_pp = np.concatenate([train['bert_embed'], train['emoji']['emoji'],\n",
    "                             np.expand_dims(train['emoji']['emoji_positive'], axis = 1), np.expand_dims(train['emoji']['emoji_negative'], axis = 1),\n",
    "                         train['punc'], train['onom'], train['init']], axis = 1)\n",
    "\n",
    "X_train_pos = np.concatenate([train['pos'], train['bert_embed']], axis = 1)\n",
    "\n",
    "X_train_pp_pos = np.concatenate([train['emoji']['emoji'],np.expand_dims(train['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(train['emoji']['emoji_negative'], axis = 1), train['pos'],train['punc'],\n",
    "                                 train['onom'], train['init'], train['bert_embed']], axis = 1)\n",
    "\n",
    "X_train_pp_pos_pol = np.concatenate([train['emoji']['emoji'],np.expand_dims(train['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(train['emoji']['emoji_negative'], axis = 1), train['pos'],train['punc'],\n",
    "                                 train['onom'], train['init'], train['bert_embed'], train['polarity']], axis = 1)\n",
    "\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective = 'binary:logistic', colsample_bytree = 0.789781955207551, learning_rate = 0.063062124248497, max_depth= 9, min_child_weight= 4, n_estimators= 173, subsample= 0.820461551935249) #bs, pos, pp, polarity\n",
    "randomf_model = RandomForestClassifier(max_depth = 26, min_samples_leaf = 4, min_samples_split = 7,n_estimators = 333) #rs, pos, pp\n",
    "hist_model =  HistGradientBoostingClassifier(learning_rate = 0.11711623246492987,max_depth = 14, min_samples_leaf = 13) #bs, pos, polarity, pp \n",
    "logi_model = LogisticRegression(C = 6.803016780839785, penalty = 'l2',max_iter=10000)  #bs, pos, polarity, pp \n",
    "ada_model = AdaBoostClassifier(learning_rate = 0.4474468937875752, n_estimators = 180) #bs, pos pp pola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diz = {'XGB': xgb_model, 'Random F': randomf_model, 'Hist': hist_model, 'Logistic': logi_model, 'Ada': ada_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bma_python.BMA(model_diz, X_train_pp_pos_pol, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(colsample_bytree = 0.7776353921686654, learning_rate =  0.063062124248497, max_depth= 9, min_child_weight= 4, n_estimators= 173, subsample= 0.834149882785828)\n",
    "hist_model =  HistGradientBoostingClassifier(learning_rate = 0.11711623246492987,max_depth = 14, min_samples_leaf = 13) #bs, pos, polarity, pp \n",
    "logi_model = LogisticRegression(C = 6.803016780839785, penalty = 'l2',max_iter=10000)  #bs, pos, polarity, pp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_pp_pos_pol, y)\n",
    "hist_model.fit(X_train_pp_pos_pol, y)\n",
    "logi_model.fit(X_train_pp_pos_pol, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/semeval_test3a_irony.p', 'rb') as handle:\n",
    "    semeval = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_pos = np.concatenate([semeval['pos'], semeval['bert_embed']], axis = 1)\n",
    "semeval_pp_pos_pol = np.concatenate([semeval['emoji']['emoji'],np.expand_dims(semeval['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(semeval['emoji']['emoji_negative'], axis = 1), semeval['pos'],semeval['punc'],\n",
    "                         semeval['onom'], semeval['init'], semeval['bert_embed'], semeval['polarity']], axis = 1)\n",
    "semeval_pp_pos = np.concatenate([semeval['emoji']['emoji'],np.expand_dims(semeval['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(semeval['emoji']['emoji_negative'], axis = 1), semeval['pos'],semeval['punc'],\n",
    "                                 semeval['onom'], semeval['init'], semeval['bert_embed']], axis = 1)\n",
    "y_semeval = semeval['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out1 = bma_python.inference_bma(xgb_model, semeval_pp_pos_pol, outputs['Weights'].loc['XGB'])\n",
    "out2 = bma_python.inference_bma(hist_model, semeval_pp_pos_pol, outputs['Weights'].loc['Hist'])\n",
    "out3 = bma_python.inference_bma(logi_model, semeval_pp_pos_pol, outputs['Weights'].loc['Logistic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_test = np.argmax(np.sum((out2, out3), axis = 0), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_semeval, sum_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
