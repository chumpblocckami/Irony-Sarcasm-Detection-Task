{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from tqdm import tqdm\n",
    "import bma_python\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/features_training_sarc_twitter.p', 'rb') as handle:\n",
    "    train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = train['bert_embed']\n",
    "\n",
    "X_train_pp = np.concatenate([train['bert_embed'], train['emoji']['emoji'],\n",
    "                             np.expand_dims(train['emoji']['emoji_positive'], axis = 1), np.expand_dims(train['emoji']['emoji_negative'], axis = 1),\n",
    "                         train['punc'], train['onom'], train['init']], axis = 1)\n",
    "\n",
    "X_train_pos = np.concatenate([train['pos'], train['bert_embed']], axis = 1)\n",
    "\n",
    "X_train_pp_pos = np.concatenate([train['emoji']['emoji'],np.expand_dims(train['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(train['emoji']['emoji_negative'], axis = 1), train['pos'],train['punc'],\n",
    "                                 train['onom'], train['init'], train['bert_embed']], axis = 1)\n",
    "\n",
    "X_train_pp_pos_pol = np.concatenate([train['emoji']['emoji'],np.expand_dims(train['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(train['emoji']['emoji_negative'], axis = 1), train['pos'],train['punc'],\n",
    "                                 train['onom'], train['init'], train['bert_embed'], train['polarity']], axis = 1)\n",
    "\n",
    "y = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(colsample_bytree = 0.7776353921686654, learning_rate =  0.063062124248497, max_depth= 9, min_child_weight= 4, n_estimators= 173, subsample= 0.834149882785828)\n",
    "randomf_model = RandomForestClassifier(max_depth = 18, min_samples_leaf = 8, min_samples_split = 2, n_estimators = 193)\n",
    "hist_model =  HistGradientBoostingClassifier(learning_rate = 0.09137860709617293,max_depth = 23, min_samples_leaf = 16) #pos, polarity, pp random\n",
    "logi_model = LogisticRegression(C =  6.3851824328733695, penalty = 'l2',max_iter=10000)  #pos, polarity, bayes\n",
    "ada_model = AdaBoostClassifier(learning_rate = 0.9679679358717436, n_estimators = 158) # pos pp bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_diz = {'XGB': xgb_model, 'Random F': randomf_model, 'Hist': hist_model, 'Logistic': logi_model, 'Ada': ada_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bma_python.BMA(model_diz, X_train_pp_pos_pol, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../data/bma_results_sarcasm.p', 'wb') as fp:\n",
    "    pickle.dump(outputs, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bma_results_sarcasm.p', 'rb') as handle:\n",
    "    outputs = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_pp_pos_pol, y)\n",
    "logi_model.fit(X_train_pp_pos_pol, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomf_model.fit(X_train_pp_pos_pol, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sarcasm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/ghosh_test_sarc.p', 'rb') as handle:\n",
    "    ghosh_test = pickle.load(handle)\n",
    "with open('../data/riloff_test_sarc.p', 'rb') as handle:\n",
    "    riloff_test = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghosh_pos = np.concatenate([ghosh_test['pos'], ghosh_test['bert_embed']], axis = 1)\n",
    "ghosh_pp_pos_pol = np.concatenate([ghosh_test['emoji']['emoji'],np.expand_dims(ghosh_test['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(ghosh_test['emoji']['emoji_negative'], axis = 1), ghosh_test['pos'],ghosh_test['punc'],\n",
    "                                 ghosh_test['onom'], ghosh_test['init'], ghosh_test['bert_embed'], ghosh_test['polarity']], axis = 1)\n",
    "ghosh_pp_pos = np.concatenate([ghosh_test['emoji']['emoji'],np.expand_dims(ghosh_test['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(ghosh_test['emoji']['emoji_negative'], axis = 1), ghosh_test['pos'],ghosh_test['punc'],\n",
    "                                 ghosh_test['onom'], ghosh_test['init'], ghosh_test['bert_embed']], axis = 1)\n",
    "\n",
    "y_ghosh = ghosh_test['label']\n",
    "\n",
    "riloff_pos =  np.concatenate([riloff_test['pos'], riloff_test['bert_embed']], axis = 1)\n",
    "riloff_pp_pos_pol = np.concatenate([riloff_test['emoji']['emoji'],np.expand_dims(riloff_test['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(riloff_test['emoji']['emoji_negative'], axis = 1), riloff_test['pos'],riloff_test['punc'],\n",
    "                                 riloff_test['onom'], riloff_test['init'], riloff_test['bert_embed'], riloff_test['polarity']], axis = 1)\n",
    "\n",
    "riloff_pp_pos = np.concatenate([riloff_test['emoji']['emoji'],np.expand_dims(riloff_test['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(riloff_test['emoji']['emoji_negative'], axis = 1), riloff_test['pos'],riloff_test['punc'],\n",
    "                                 riloff_test['onom'], riloff_test['init'], riloff_test['bert_embed']], axis = 1)\n",
    "\n",
    "y_riloff = riloff_test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = bma_python.inference_bma(xgb_model, riloff_pp_pos_pol, outputs['Weights'].loc['XGB'])\n",
    "out2 = bma_python.inference_bma(randomf_model, riloff_pp_pos_pol, outputs['Weights'].loc['Random F'])\n",
    "out3 = bma_python.inference_bma(logi_model, riloff_pp_pos_pol, outputs['Weights'].loc['Logistic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_test = np.argmax(np.sum((out1, out2), axis = 0), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_riloff, sum_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_riloff, sum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = bma_python.inference_bma(xgb_model, ghosh_pp_pos_pol, outputs['Weights'].loc['XGB'])\n",
    "out2 = bma_python.inference_bma(randomf_model, ghosh_pp_pos_pol, outputs['Weights'].loc['Random F'])\n",
    "out3 = bma_python.inference_bma(logi_model, ghosh_pp_pos_pol, outputs['Weights'].loc['Logistic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_test = np.argmax(np.sum((out1, out2), axis = 0), axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_ghosh, sum_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_ghosh, sum_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
