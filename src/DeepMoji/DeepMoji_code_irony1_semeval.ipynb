{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import re\n",
    "import textattack as ta \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('D:/Data_Science_all/MSC_2_anno/Tesi_Irony_Sarcasm/data/final_training_semeval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].str.replace(r'#([^\\s:]+)', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Findall(name)']= data[\"text\"].str.findall('(#\\w*)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['Findall(name)'].apply(lambda x: len(x)) == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_link(x):\n",
    "    text = re.sub(r'^https?:\\/\\/.[\\r\\n]', '', x, flags=re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "#removes other link \n",
    "def remove_link2(x):\n",
    "    text = re.sub(r'http\\S+', '', x)\n",
    "    return text    \n",
    "data['text'] = data['text'].apply(remove_link)\n",
    "data['text'] = data['text'].apply(remove_link2)\n",
    "data['text']  = data['text'].replace('\\s+', ' ', regex=True)\n",
    "data['list'] = data.text.apply(lambda x: x.split(' '))\n",
    "data['len_list'] = data.list.str.len()\n",
    "data = data[data.len_list > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import pre-build vocabulary \n",
    "from deepmoji.global_variables import get_vocabulary\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer\n",
    "\n",
    "st = SentenceTokenizer(get_vocabulary(), 50)\n",
    "test_sentences = data.text\n",
    "tokens, infos, stats = st.tokenize_sentences(test_sentences)\n",
    "\n",
    "# print(tokens)\n",
    "# print(infos)\n",
    "# print(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH, \\\n",
    "    get_vocabulary\n",
    "from deepmoji.model_def import deepmoji_feature_encoding\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer\n",
    "\n",
    "TEST_SENTENCES =  data.text.to_list()\n",
    "\n",
    "maxlen = 20\n",
    "batch_size = 16\n",
    "\n",
    "# print('Tokenizing using dictionary from {}'.format(VOCAB_PATH))\n",
    "st = SentenceTokenizer(get_vocabulary(), maxlen, ignore_sentences_with_only_custom=False)\n",
    "tokenized, _, _ = st.tokenize_sentences(TEST_SENTENCES)\n",
    "path = \"D:/Data_Science_all/MSC_2_anno/Tesi_Irony_Sarcasm/Code/DeepMoji/model/weights/deepmoji-checkpoint-cd2cb10d-83c1-438f-aa12-88a2eab3cdc1.hdf5\"\n",
    "# print('Loading model from {}.'.format(PRETRAINED_PATH))\n",
    "model = deepmoji_feature_encoding(maxlen, PRETRAINED_PATH) #PRETRAINED_PATH\n",
    "model.summary()\n",
    "\n",
    "# print('Encoding texts..')\n",
    "encoding = model.predict(tokenized)\n",
    "\n",
    "# print('First 5 dimensions for sentence: {}'.format(TEST_SENTENCES[0]))\n",
    "# print(encoding[0, :5])\n",
    "\n",
    "# Now you could visualize the encodings to see differences,\n",
    "# run a logistic regression classifier on top,\n",
    "# or basically anything you'd like to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\Code\\Deep_moji_feature\\train\\irony\\sentence_emoji_train_semeval', encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\Code\\Deep_moji_feature\\train\\irony\\y_emoji_train_semeval', np.array(data.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(tokens,data.label, test_size=0.05, stratify = data.label,  random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, stratify = y_train, test_size=0.05, random_state=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "  \n",
    "\"\"\"Finetuning example.\n",
    "Trains the DeepMoji model on the kaggle insults dataset, using the 'chain-thaw'\n",
    "finetuning method and the accuracy metric. See the blog post at\n",
    "https://medium.com/@bjarkefelbo/what-can-we-learn-from-emojis-6beb165a5ea0\n",
    "for more information. Note that results may differ a bit due to slight\n",
    "changes in preprocessing and train/val/test split.\n",
    "The 'chain-thaw' method does the following:\n",
    "0) Load all weights except for the softmax layer. Extend the embedding layer if\n",
    "   necessary, initialising the new weights with random values.\n",
    "1) Freeze every layer except the last (softmax) layer and train it.\n",
    "2) Freeze every layer except the first layer and train it.\n",
    "3) Freeze every layer except the second etc., until the second last layer.\n",
    "4) Unfreeze all layers and train entire model.\n",
    "\"\"\"\n",
    "\n",
    "from deepmoji.finetuning import (\n",
    "    load_benchmark,\n",
    "    finetune,sampling_generator)\n",
    "from deepmoji.global_variables import PRETRAINED_PATH, get_vocabulary\n",
    "from deepmoji.model_def import deepmoji_transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "maxlen = 20\n",
    "# Set up model and finetune. Note that we have to extend the embedding layer\n",
    "# with the number of tokens added to the vocabulary.\n",
    "model = deepmoji_transfer(nb_classes, maxlen, PRETRAINED_PATH, embed_dropout_rate=0.8, final_dropout_rate=0.7)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, hist = finetune(model, [X_train, X_val, X_test], [y_train, y_val, y_test], nb_classes,\n",
    "                          nb_epochs = 3,  method='chain-thaw', epoch_size = X_train.shape[0], batch_size = 24)\n",
    "print('Acc: {}'.format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.grid(linestyle = 'dashed')\n",
    "plt.plot(n_epochs, accuracy_train, c = 'green')\n",
    "plt.plot(n_epochs, accuracy_val)\n",
    "\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}'))\n",
    "plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "plt.title('Accuracy Metric with respect to DeepMoji Model')\n",
    "plt.legend(['Train Set', 'Validation Set'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\thesis_latex\\img\\accuracy_deepmoji_irony_semeaval.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams[\"font.weight\"] = \"bold\"\n",
    "plt.rcParams[\"axes.labelweight\"] = \"bold\"\n",
    "plt.figure(figsize = (5,5))\n",
    "plt.grid(linestyle = 'dashed')\n",
    "plt.plot(n_epochs, loss_train, c = 'green')\n",
    "plt.plot(n_epochs, loss_val)\n",
    "plt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}'))\n",
    "plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "plt.title('Cross Entropy Loss with respect to DeepMoji Model')\n",
    "plt.legend(['Train Set', 'Validation Set'])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.savefig(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\thesis_latex\\img\\loss_deepmoji_irony_semeval.png', dpi=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmoji.model_def import deepmoji_architecture\n",
    "final_model = deepmoji_architecture(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.load_weights(\"D:/Data_Science_all/MSC_2_anno/Tesi_Irony_Sarcasm/Code/DeepMoji/model/weights/deepmoji-checkpoint-0afd84bb-7905-46c4-9f52-0e13ad6cb91e.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem = pd.read_csv('D:/Data_Science_all/MSC_2_anno/Tesi_Irony_Sarcasm/data/SemEval2018-Task3/datasets/goldtest_TaskA/SemEval2018-T3_gold_test_taskA_emoji.txt', sep='\\t')\n",
    "sem.rename({'Tweet text': 'text', 'Label' : 'label'}, axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepmoji.global_variables import PRETRAINED_PATH, VOCAB_PATH, \\\n",
    "    get_vocabulary\n",
    "from deepmoji.model_def import deepmoji_feature_encoding\n",
    "from deepmoji.sentence_tokenizer import SentenceTokenizer\n",
    "\n",
    "TEST_SENTENCES = sem.text.to_list()\n",
    "maxlen = 20\n",
    "batch_size = 16\n",
    "\n",
    "# print('Tokenizing using dictionary from {}'.format(VOCAB_PATH))\n",
    "st = SentenceTokenizer(get_vocabulary(), maxlen, ignore_sentences_with_only_custom=False)\n",
    "tokenized, _, _ = st.tokenize_sentences(TEST_SENTENCES)\n",
    "\n",
    "# print('Loading model from {}.'.format(PRETRAINED_PATH))\n",
    "model = deepmoji_feature_encoding(maxlen, PRETRAINED_PATH)\n",
    "\n",
    "# print('Encoding texts..')\n",
    "encoding = model.predict(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\Code\\Deep_moji_feature\\test\\sentence_emoji_sem', encoding)\n",
    "np.save(r'D:\\Data_Science_all\\MSC_2_anno\\Tesi_Irony_Sarcasm\\Code\\Deep_moji_feature\\test\\y_emoji_sem', np.array(sem.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = SentenceTokenizer(get_vocabulary(), maxlen, ignore_sentences_with_only_custom=False)\n",
    "test_sentences = sem.text.to_numpy()\n",
    "\n",
    "tokens, infos, stats = st.tokenize_sentences(test_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_test = sem.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "pred = final_model.predict(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, f1_score\n",
    "print('DeepMoji')\n",
    "print(classification_report(pred.argmax(axis = -1),y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(pred.argmax(axis = -1),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lab(x):\n",
    "    new_lab_list = []\n",
    "    for i in x:\n",
    "        if i == 0:\n",
    "            new_lab = '1:1'\n",
    "        else:\n",
    "            new_lab =  '2:0'\n",
    "            \n",
    "        new_lab_list.append(new_lab)\n",
    "        \n",
    "    return new_lab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lab(x):\n",
    "    new_lab_list = []\n",
    "    for i in x:\n",
    "        if i == 0:\n",
    "            new_lab = '1:1'\n",
    "        else:\n",
    "            new_lab =  '2:0'\n",
    "            \n",
    "        new_lab_list.append(new_lab)\n",
    "        \n",
    "    return new_lab_list\n",
    "\n",
    "def mark_error(actual, predicted):\n",
    "    mark_list = []\n",
    "    for i,j in zip(actual, predicted):\n",
    "        if i != j:\n",
    "            mark = '+'\n",
    "        else:\n",
    "            mark = np.nan\n",
    "            \n",
    "        mark_list.append(mark)\n",
    "        \n",
    "    return mark_list\n",
    "\n",
    "def get_proba_distrib(clf_proba):\n",
    "    proba_ast = []\n",
    "    for i,j in zip(clf_proba[:,0], clf_proba[:,1]):\n",
    "        if i > j:\n",
    "            proba = ['*{}'.format(str(i.round(5))), str(j.round(5))]\n",
    "        else:\n",
    "            proba = [str(i.round(5)), '*{}'.format(str(j.round(5)))]\n",
    "            \n",
    "        proba_ast.append(proba)\n",
    "        \n",
    "    return np.array(proba_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_distrib(clf_proba):\n",
    "    proba_ast = []\n",
    "    for i,j in zip(clf_proba[:,0], clf_proba[:,1]):\n",
    "        if i > j:\n",
    "            proba = ['*{}'.format(str(i.round(5))), str(j.round(5))]\n",
    "        else:\n",
    "            proba = [str(i.round(5)), '*{}'.format(str(j.round(5)))]\n",
    "            \n",
    "        proba_ast.append(proba)\n",
    "        \n",
    "    return np.array(proba_ast)\n",
    "\n",
    "def get_outpupt_bma(clf, x, ground_truth):\n",
    "    \n",
    "    pred = clf.predict(x).argmax(axis = -1)\n",
    "    \n",
    "    actual = normalize_lab(ground_truth)\n",
    "    predicted = normalize_lab(pred)\n",
    "    \n",
    "    error = mark_error(actual, predicted)\n",
    "    conta = 0\n",
    "    lista_ins = []\n",
    "    for i in range(len(x)):\n",
    "        conta += 1\n",
    "        if conta == int(len(x)/10) + 2:\n",
    "            conta = 1\n",
    "     \n",
    "        lista_ins.append(conta)  \n",
    "        \n",
    "    instanc = lista_ins\n",
    "    \n",
    "    predict_proba = clf.predict(x)\n",
    "    \n",
    "    distribution = get_proba_distrib(predict_proba)\n",
    "    \n",
    "    final_df = pd.DataFrame(instanc, columns=['inst#'])\n",
    "    \n",
    "    final_df['actual'] = actual\n",
    "    \n",
    "    final_df['predicted'] = predicted\n",
    "    \n",
    "    final_df['error'] = error\n",
    "\n",
    "    final_df['distribution'] = distribution[:, 0]\n",
    "    \n",
    "    final_df[''] = distribution[:,1]\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_outpupt_bma(final_model, tokens, sem.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D:/Data_Science_all/MSC_2_anno/Tesi_Irony_Sarcasm/Code/BMA/results_semeval/input/prediction_file/deepmoji_chain.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
