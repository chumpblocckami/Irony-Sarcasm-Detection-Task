{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/features_training_irony_twitter_semeval.p', 'rb') as handle:\n",
    "    train = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embed = train['bert_embed']\n",
    "\n",
    "X_train_pp = np.concatenate([train['bert_embed'], train['emoji']['emoji'],\n",
    "                             np.expand_dims(train['emoji']['emoji_positive'], axis = 1), np.expand_dims(train['emoji']['emoji_negative'], axis = 1),\n",
    "                         train['punc'], train['onom'], train['init']], axis = 1)\n",
    "\n",
    "X_train_pos = np.concatenate([train['pos'], train['bert_embed']], axis = 1)\n",
    "\n",
    "X_train_pp_pos = np.concatenate([train['emoji']['emoji'],np.expand_dims(train['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(train['emoji']['emoji_negative'], axis = 1), train['pos'],train['punc'],\n",
    "                                 train['onom'], train['init'], train['bert_embed']], axis = 1)\n",
    "\n",
    "X_train_pp_pos_pol = np.concatenate([train['emoji']['emoji'],np.expand_dims(train['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(train['emoji']['emoji_negative'], axis = 1), train['pos'],train['punc'],\n",
    "                                 train['onom'], train['init'], train['bert_embed'], train['polarity']], axis = 1)\n",
    "\n",
    "y_train = train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pol = np.concatenate([train['bert_embed'], train['polarity']], axis =1)\n",
    "X_train_pos_pol = np.concatenate([train['bert_embed'], train['polarity'], train['pos']], axis = 1)\n",
    "X_train_pp_pol = np.concatenate([train['bert_embed'], train['emoji']['emoji'],\n",
    "                             np.expand_dims(train['emoji']['emoji_positive'], axis = 1), np.expand_dims(train['emoji']['emoji_negative'], axis = 1),\n",
    "                         train['punc'], train['onom'], train['init']], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def get_val_metrics(clf): \n",
    "    split0 = clf.cv_results_['split0_test_score'][clf.best_index_]\n",
    "    split1 = clf.cv_results_['split1_test_score'][clf.best_index_]\n",
    "    split2 = clf.cv_results_['split2_test_score'][clf.best_index_]\n",
    "    split3 = clf.cv_results_['split3_test_score'][clf.best_index_]\n",
    "    split4 = clf.cv_results_['split4_test_score'][clf.best_index_]\n",
    "    split5 = clf.cv_results_['split5_test_score'][clf.best_index_]\n",
    "    fold_results = [split0,split1, split2, split3, split4, split5]\n",
    "    \n",
    "    return fold_results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from scipy.stats import randint as sp_randint\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "# Define dictionary with performance metrics\n",
    "scoring = {'accuracy':make_scorer(accuracy_score), \n",
    "           'precision':make_scorer(precision_score),\n",
    "           'recall':make_scorer(recall_score), \n",
    "           'f1_score':make_scorer(f1_score)}\n",
    "from imblearn.pipeline import Pipeline\n",
    "# Import required libraries for machine learning classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.experimental import enable_hist_gradient_boosting \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy import stats\n",
    "# Instantiate the machine learning classifiers\n",
    "log_model = LogisticRegression(max_iter=500)\n",
    "dtr_model = HistGradientBoostingClassifier()\n",
    "rfc_model = RandomForestClassifier()\n",
    "gnb_model = AdaBoostClassifier()\n",
    "xgb_model = xgb.XGBClassifier(objective = 'binary:logistic') #tree_method = 'gpu_hist'\n",
    "nb_model = GaussianNB()\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Define the models evaluation function\n",
    "def models_evaluation(X, y, folds, epoch, metric = 'accuracy'):\n",
    "    \n",
    "    '''\n",
    "    X : data set features\n",
    "    y : data set target\n",
    "    folds : number of cross-validation folds\n",
    "    \n",
    "    '''\n",
    "    diz = {}\n",
    "    rand_list_xgb = {'n_estimators': stats.randint(200, 500),\n",
    "              'learning_rate': stats.uniform(0.01, 0.6),\n",
    "              'subsample': stats.uniform(0.3, 0.9),\n",
    "              'max_depth': stats.randint(3, 30),\n",
    "              'min_child_weight':stats.randint(1, 20)\n",
    "             }\n",
    "    rand_list_svm = {\"C\": stats.uniform(2, 20),\"gamma\": stats.uniform(0.1, 1), 'kernel': ['linear', 'rbf', 'sigmoid']}\n",
    "    rand_list_reg = { 'C': stats.uniform(0.1, 10), 'penalty' : ['l2'], 'solver' : ['liblinear', 'saga']}\n",
    "    rand_list_hist = {'max_depth': stats.randint(3, 30), 'min_samples_leaf': stats.randint(1, 20), 'learning_rate': stats.uniform(0.001, 0.1)}\n",
    "    rand_list_rf = {'max_depth': stats.randint(3, 30), 'min_samples_leaf':  stats.randint(1, 20), 'min_samples_split': stats.randint(1, 20), 'n_estimators':  stats.randint(50, 500)}\n",
    "    rand_list_ada = {'n_estimators':  stats.randint(50, 500), 'learning_rate' : stats.uniform(0.001, 0.1)}\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "    strat = StratifiedKFold(n_splits = folds, random_state = None)\n",
    "    \n",
    "    \n",
    "    pipeline = Pipeline([('sampling', RandomUnderSampler()),\n",
    "        ('classification',dtr_model)])\n",
    "    random_grid = {'classification__' + key: rand_list_hist[key] for key in rand_list_hist}\n",
    "    clf_randomsearch_hgb = RandomizedSearchCV(pipeline, random_grid, n_iter = epoch, cv = strat, scoring = metric,  n_jobs=6, verbose = 2)\n",
    "    clf_randomsearch_hgb.fit(X, y)\n",
    "    diz['Hgboost'] = get_val_metrics(clf_randomsearch_hgb)\n",
    "    std = clf_randomsearch_hgb.cv_results_['std_test_score'][clf_randomsearch_hgb.best_index_]\n",
    "    print(\"Best configuration for Hist G.Boost: {}\\n Metric score: {} and std score: {}\".format(clf_randomsearch_hgb.best_params_, clf_randomsearch_hgb.best_score_, std))\n",
    "    \n",
    "    pipeline = Pipeline([('sampling', RandomUnderSampler()),\n",
    "        ('classification',rfc_model)])\n",
    "    random_grid = {'classification__' + key: rand_list_rf[key] for key in rand_list_rf}    \n",
    "    clf_randomsearch_rf = RandomizedSearchCV(pipeline, random_grid, n_iter = epoch, cv = strat, scoring = metric,  n_jobs=6, verbose = 2)\n",
    "    clf_randomsearch_rf.fit(X, y)\n",
    "    std = clf_randomsearch_rf.cv_results_['std_test_score'][clf_randomsearch_rf.best_index_]\n",
    "    diz['RandomForest'] = get_val_metrics(clf_randomsearch_rf)\n",
    "    print(\"Best configuration for Random Forest: {}\\n Metric score: {} and std score: {}\".format(clf_randomsearch_rf.best_params_, clf_randomsearch_rf.best_score_, std))\n",
    "    \n",
    "    pipeline = Pipeline([('sampling', RandomUnderSampler()),\n",
    "        ('classification',xgb_model)])\n",
    "    random_grid = {'classification__' + key: rand_list_xgb[key] for key in rand_list_xgb}    \n",
    "    clf_randomsearch_xgb = RandomizedSearchCV(pipeline,random_grid, n_iter = epoch, cv = strat, scoring = metric,  n_jobs=6, verbose = 2)\n",
    "    clf_randomsearch_xgb.fit(X, y)\n",
    "    diz['XgBoost'] = get_val_metrics(clf_randomsearch_xgb)\n",
    "    std = clf_randomsearch_xgb.cv_results_['std_test_score'][clf_randomsearch_xgb.best_index_]\n",
    "    print(\"Best configuration for XG.Boost: {}\\n Metric score: {} and std score: {}\".format(clf_randomsearch_xgb.best_params_, clf_randomsearch_xgb.best_score_, std))\n",
    "    \n",
    "    pipeline = Pipeline([('sampling', RandomUnderSampler()),\n",
    "        ('classification',gnb_model)])\n",
    "    random_grid = {'classification__' + key: rand_list_ada[key] for key in rand_list_ada}      \n",
    "    clf_randomsearch_ada = RandomizedSearchCV(pipeline, random_grid, n_iter = epoch, cv = strat, scoring = metric,  n_jobs=6, verbose = 2)\n",
    "    clf_randomsearch_ada.fit(X, y)\n",
    "    diz['AdaBoost'] = get_val_metrics(clf_randomsearch_ada)\n",
    "    std = clf_randomsearch_ada.cv_results_['std_test_score'][clf_randomsearch_ada.best_index_]\n",
    "    print(\"Best configuration for Ada Boost: {}\\n Metric score: {} and std score: {}\".format(clf_randomsearch_ada.best_params_, clf_randomsearch_ada.best_score_, std))\n",
    "    \n",
    "    pipeline = Pipeline([('sampling', RandomUnderSampler()),\n",
    "        ('classification',log_model)])\n",
    "    random_grid = {'classification__' + key: rand_list_reg[key] for key in rand_list_reg}       \n",
    "    clf_randomsearch_reg = RandomizedSearchCV(pipeline, random_grid, n_iter = epoch, cv = strat, scoring = metric,  n_jobs=6, verbose = 2)\n",
    "    clf_randomsearch_reg.fit(X, y)\n",
    "    diz['Logistic'] = get_val_metrics(clf_randomsearch_reg)\n",
    "    std = clf_randomsearch_reg.cv_results_['std_test_score'][clf_randomsearch_reg.best_index_]\n",
    "    print(\"Best configuration for Logistic Regression: {}\\n Metric score: {} and std score: {}\".format(clf_randomsearch_reg.best_params_, clf_randomsearch_reg.best_score_, std))\n",
    "    \n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Embedding features')\n",
    "score = models_evaluation(X_train_embed, y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PP features\")\n",
    "score2 = models_evaluation(np.nan_to_num(X_train_pp), y_train, 6, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pos features\")\n",
    "score3 = models_evaluation(X_train_pos, y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pos + PP features\")\n",
    "score4 = models_evaluation(np.nan_to_num(X_train_pp_pos), y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pos + PP features + Polarity\")\n",
    "score5 = models_evaluation(np.nan_to_num(X_train_pp_pos_pol), y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Polarity')\n",
    "score6 = models_evaluation(X_train_pol, y_train, 6, 10)\n",
    "print('Pos and Polarity')\n",
    "score7 = models_evaluation(X_train_pos_pol, y_train, 6, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PP and Polarity')\n",
    "score8 = models_evaluation(np.nan_to_num(X_train_pp_pol), y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = ['POL', 'POS+POL', 'PP+POL']\n",
    "list_score = [score6, score7, score8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_score = [score,score2,score3, score4, score5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = [\"Embedding\",\"PP\",\"POS\",\"POS+PP\",\"POS+PP+POL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_scores = {}\n",
    "for i in range(len(list_score)):\n",
    "    diz_scores['{}'.format(features_name[i])] = list_score[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('bayes_search_irony_semeval_otherfeat.p', 'wb') as fp:\n",
    "    pickle.dump(diz_scores, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(diz_scores).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(samples, n_bootstrap, size_samples, ic = 0.95): #size sample n splits \n",
    "    diz = {}\n",
    "    samples = np.array(list(samples))\n",
    "    x_mean = np.mean(samples)\n",
    "    samples_boot = []\n",
    "    for i in range(n_bootstrap):\n",
    "        samples_boot.append(np.mean(np.random.choice(np.squeeze(samples), size_samples)))\n",
    "    scarti = samples_boot - x_mean\n",
    "    v = 100 - ic*100\n",
    "    pinf = 100 - v/2\n",
    "    psup = 100 - pinf\n",
    "    lim_inf = x_mean - np.percentile(scarti, pinf)\n",
    "    lim_sup = x_mean - np.percentile(scarti, psup)\n",
    "    diz['Mean'] = x_mean\n",
    "    diz['Lower'] = lim_inf\n",
    "    diz['Upper'] = lim_sup\n",
    "    return diz\n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_boostrap(df, column):    \n",
    "    diz = {}\n",
    "    diz2 = {}\n",
    "    diz['Hgboost'] = bootstrap(df[df['index'] == 'Hgboost'][column], 50, 6, 0.95)\n",
    "    diz['RandomForest'] = bootstrap(df[df['index'] == 'RandomForest'][column], 50, 6, 0.95)\n",
    "    diz['XgBoost']  = bootstrap(df[df['index'] == 'XgBoost'][column], 50, 6, 0.95)\n",
    "    diz['AdaBoost'] = bootstrap(df[df['index'] == 'Adaboost'][column], 50, 6, 0.95)\n",
    "    diz['Logistic'] = bootstrap(df[df['index'] == 'Logistic'][column], 50, 6, 0.95)\n",
    "    return pd.DataFrame(diz).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = compute_boostrap(data, \"POL\").reset_index()\n",
    "embed2 = compute_boostrap(data, \"POS+POL\").reset_index()\n",
    "embed3 = compute_boostrap(data, \"PP+POL\").reset_index()\n",
    "embed['Features'] = 'POL'\n",
    "embed2['Features'] = 'POS+POL'\n",
    "embed3['Features'] = 'PP+POL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = compute_boostrap(data, \"Embedding\").reset_index()\n",
    "embed2 = compute_boostrap(data, \"PP\").reset_index()\n",
    "embed3 = compute_boostrap(data, \"POS\").reset_index()\n",
    "embed4 = compute_boostrap(data, \"POS+PP\").reset_index()\n",
    "embed5 = compute_boostrap(data, \"POS+PP+POL\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed['Features'] = 'Embedding'\n",
    "embed2['Features'] = 'PP'\n",
    "embed3['Features'] = 'POS'\n",
    "embed4['Features'] = 'POS+PP'\n",
    "embed5['Features'] = 'POS+PP+POL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = pd.concat([embed,embed2,embed3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = pd.concat([embed, embed2, embed3, embed4, embed5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score.to_csv('../data/Optimization/Irony/random_search_semeval_otherfeat.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "def bayes_opt(X_train, y_train, fold, n_iter):\n",
    "    diz = {}\n",
    "    global count \n",
    "    \n",
    "    log_model = LogisticRegression(max_iter=500)\n",
    "    dtr_model = HistGradientBoostingClassifier()\n",
    "    rfc_model = RandomForestClassifier()\n",
    "    ada_model = AdaBoostClassifier()\n",
    "    xgb_model = xgb.XGBClassifier(objective = 'binary:logistic')\n",
    "\n",
    "\n",
    "    rand_list_xgb = {'n_estimators': [int(x) for x in np.linspace(50, 300, num=251)],\n",
    "              'learning_rate':  np.linspace(1e-3, 1, num=500),\n",
    "              'subsample': [np.random.uniform(0.3, 0.9) for _ in range(200)],\n",
    "              'max_depth': list(range(3,21)),\n",
    "              'colsample_bytree': [np.random.uniform(0.5, 0.9) for _ in range(200)],\n",
    "              'min_child_weight':list(range(1,21))\n",
    "             }\n",
    "    rand_list_reg = { 'C': [np.random.uniform(0.1, 10) for _ in range(200)], 'penalty' : ['l2']}\n",
    "    rand_list_hist = {'max_depth': list(range(3,21)), 'min_samples_leaf': list(range(1,21)), 'learning_rate': np.linspace(1e-3, 1, num=500)}\n",
    "    rand_list_rf = {'max_depth': list(range(3,21)), 'min_samples_leaf':  list(range(1,21)), 'min_samples_split': list(range(2,21)), 'n_estimators':   [int(x) for x in np.linspace(50, 300, num=251)]}\n",
    "    rand_list_ada = {'n_estimators':   [int(x) for x in np.linspace(50, 300, num=251)], 'learning_rate':  np.linspace(1e-3, 1, num=500)}\n",
    "\n",
    "\n",
    "    gb_bayes_reglog = BayesSearchCV(log_model, rand_list_reg, n_iter=n_iter, cv=fold,\n",
    "                             random_state=1, n_jobs=6, refit=True, scoring = 'accuracy')\n",
    "    \n",
    "    gb_bayes_xgb = BayesSearchCV(xgb_model, rand_list_xgb, n_iter=n_iter, cv=fold,\n",
    "                             random_state=1, n_jobs=6, refit=True, scoring = 'accuracy')\n",
    "\n",
    "    gb_bayes_hist = BayesSearchCV(dtr_model, rand_list_hist, n_iter=n_iter, cv=fold,\n",
    "                             random_state=1, n_jobs=6, refit=True, scoring = 'accuracy')\n",
    "\n",
    "    gb_bayes_rf = BayesSearchCV(rfc_model, rand_list_rf, n_iter=n_iter, cv=fold,\n",
    "                             random_state=1, n_jobs=6, refit=True, scoring = 'accuracy')\n",
    "\n",
    "    gb_bayes_ada = BayesSearchCV(ada_model, rand_list_ada, n_iter=n_iter, cv=fold,\n",
    "                            random_state=1, n_jobs=6, refit=True, scoring = 'accuracy')\n",
    "\n",
    "    count = 1\n",
    "    def on_epoch(optim_result):\n",
    "        global count\n",
    "        if count == n_iter:\n",
    "            std = gb_bayes_reglog.cv_results_['std_test_score'][gb_bayes_reglog.best_index_]\n",
    "            print(\"Params:\",gb_bayes_reglog.best_params_, \" Logistic regression score:\",gb_bayes_reglog.best_score_,' standard dev: ', std)    \n",
    "        count += 1\n",
    "        \n",
    "\n",
    "    gb_bayes_reglog.fit(X_train, y_train, callback = on_epoch)\n",
    "    diz['Logistic'] = get_val_metrics(gb_bayes_reglog)\n",
    "    count = 1\n",
    "    def on_epoch(optim_result):\n",
    "        global count\n",
    "        if count == n_iter:\n",
    "            std = gb_bayes_xgb.cv_results_['std_test_score'][gb_bayes_xgb.best_index_]\n",
    "            print(\"Params:\",gb_bayes_xgb.best_params_, \" Xgboost score:\",gb_bayes_xgb.best_score_,' standard dev: ', std)    \n",
    "        count += 1\n",
    "    gb_bayes_xgb.fit(X_train, y_train, callback = on_epoch)\n",
    "    diz['XgBoost'] = get_val_metrics(gb_bayes_xgb)\n",
    "    count = 1\n",
    "    def on_epoch(optim_result):\n",
    "        global count\n",
    "        if count == n_iter:\n",
    "            std = gb_bayes_hist.cv_results_['std_test_score'][gb_bayes_hist.best_index_]\n",
    "            print(\"Params:\",gb_bayes_hist.best_params_, \"Hist GB score:\",gb_bayes_hist.best_score_,' standard dev: ', std)    \n",
    "        count += 1\n",
    "    gb_bayes_hist.fit(X_train, y_train, callback = on_epoch)\n",
    "    diz['Hgboost'] = get_val_metrics(gb_bayes_hist)\n",
    "    count = 1\n",
    "    def on_epoch(optim_result):\n",
    "        global count\n",
    "        if count == n_iter:\n",
    "            std = gb_bayes_rf.cv_results_['std_test_score'][gb_bayes_rf.best_index_]\n",
    "            print(\"Params:\",gb_bayes_rf.best_params_, \" Random Forest score:\",gb_bayes_rf.best_score_,' standard dev: ', std)    \n",
    "        count += 1\n",
    "    gb_bayes_rf.fit(X_train, y_train, callback = on_epoch)\n",
    "    diz['RandomForest'] = get_val_metrics(gb_bayes_rf)\n",
    "    count = 1\n",
    "    def on_epoch(optim_result):\n",
    "        global count\n",
    "        if count == n_iter:\n",
    "            std = gb_bayes_ada.cv_results_['std_test_score'][gb_bayes_ada.best_index_]\n",
    "            print(\"Params:\",gb_bayes_ada.best_params_, \" Ada Boost score:\",gb_bayes_ada.best_score_,' standard dev: ', std)    \n",
    "        count += 1\n",
    "    gb_bayes_ada.fit(X_train, y_train, callback = on_epoch)\n",
    "    diz['Adaboost'] = get_val_metrics(gb_bayes_ada)\n",
    "    \n",
    "    return diz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Embedding features')\n",
    "score = bayes_opt(X_train_embed, y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PP features\")\n",
    "score2 = bayes_opt(np.nan_to_num(X_train_pp), y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pos features\")\n",
    "score3 = bayes_opt(X_train_pos, y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pos + PP features\")\n",
    "score4 = bayes_opt(np.nan_to_num(X_train_pp_pos), y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pos + PP features + Polarity\")\n",
    "score5 = bayes_opt(np.nan_to_num(X_train_pp_pos_pol), y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score6 = bayes_opt(X_train_pol, y_train, 6, 10)\n",
    "score7 = bayes_opt(X_train_pos_pol, y_train, 6, 10)\n",
    "score8 = bayes_opt(np.nan_to_num(X_train_pp_pol), y_train, 6, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_name = [\"Embedding\",\"PP\",\"POS\",\"POS+PP\",\"POS+PP+POL\"]\n",
    "list_score = [score,score2,score3, score4, score5]\n",
    "diz_scores = {}\n",
    "for i in range(len(list_score)):\n",
    "    diz_scores['{}'.format(features_name[i])] = list_score[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('bayesian_search_irony_semeval.p', 'wb') as fp:\n",
    "    pickle.dump(diz_scores, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(diz_scores).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = compute_boostrap(data, \"Embedding\").reset_index()\n",
    "embed2 = compute_boostrap(data, \"PP\").reset_index()\n",
    "embed3 = compute_boostrap(data, \"POS\").reset_index()\n",
    "embed4 = compute_boostrap(data, \"POS+PP\").reset_index()\n",
    "embed5 = compute_boostrap(data, \"POS+PP+POL\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed['Features'] = 'Embedding'\n",
    "embed2['Features'] = 'PP'\n",
    "embed3['Features'] = 'POS'\n",
    "embed4['Features'] = 'POS+PP'\n",
    "embed5['Features'] = 'POS+PP+POL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score = pd.concat([embed, embed2, embed3, embed4, embed5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score.to_csv('../data/Optimization/Irony/bayes_search_semeval_otherfeat.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BMA JAVA INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_lab(x):\n",
    "    new_lab_list = []\n",
    "    for i in x:\n",
    "        if i == 0:\n",
    "            new_lab = '1:1'\n",
    "        else:\n",
    "            new_lab =  '2:0'\n",
    "            \n",
    "        new_lab_list.append(new_lab)\n",
    "        \n",
    "    return new_lab_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mark_error(actual, predicted):\n",
    "    mark_list = []\n",
    "    for i,j in zip(actual, predicted):\n",
    "        if i != j:\n",
    "            mark = '+'\n",
    "        else:\n",
    "            mark = np.nan\n",
    "            \n",
    "        mark_list.append(mark)\n",
    "        \n",
    "    return mark_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proba_distrib(clf_proba):\n",
    "    proba_ast = []\n",
    "    for i,j in zip(clf_proba[:,0], clf_proba[:,1]):\n",
    "        if i > j:\n",
    "            proba = ['*{}'.format(str(i.round(5))), str(j.round(5))]\n",
    "        else:\n",
    "            proba = [str(i.round(5)), '*{}'.format(str(j.round(5)))]\n",
    "            \n",
    "        proba_ast.append(proba)\n",
    "        \n",
    "    return np.array(proba_ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outpupt_bma(clf, x, ground_truth):\n",
    "    \n",
    "    pred = clf.predict(x)\n",
    "    \n",
    "    actual = normalize_lab(ground_truth)\n",
    "    predicted = normalize_lab(pred)\n",
    "    \n",
    "    error = mark_error(actual, predicted)\n",
    "    conta = 0\n",
    "    lista_ins = []\n",
    "    for i in range(len(x)):\n",
    "        conta += 1\n",
    "        if conta == int(len(x)/10) + 2:\n",
    "            conta = 1\n",
    "     \n",
    "        lista_ins.append(conta)  \n",
    "        \n",
    "    instanc = lista_ins\n",
    "    \n",
    "    predict_proba = clf.predict_proba(x)\n",
    "    \n",
    "    distribution = get_proba_distrib(predict_proba)\n",
    "    \n",
    "    final_df = pd.DataFrame(instanc, columns=['inst#'])\n",
    "    \n",
    "    final_df['actual'] = actual\n",
    "    \n",
    "    final_df['predicted'] = predicted\n",
    "    \n",
    "    final_df['error'] = error\n",
    "\n",
    "    final_df['distribution'] = distribution[:, 0]\n",
    "    \n",
    "    final_df[''] = distribution[:,1]\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models for sarcasm with the best hyperparameters identified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(objective = 'binary:logistic', colsample_bytree = 0.8020639316513152, learning_rate = 0.063062124248497, max_depth= 9, min_child_weight= 4, n_estimators= 173, subsample= 0.838253733300651) #bs, pos, pp, polarity\n",
    "randomf_model = RandomForestClassifier(max_depth = 15, min_samples_leaf = 9, min_samples_split = 4,n_estimators = 13) #bs, pos, pp, pp\n",
    "hist_model =  HistGradientBoostingClassifier(learning_rate = 0.11711623246492987,max_depth = 14, min_samples_leaf = 13) #bs, pos, polarity, pp \n",
    "logi_model = LogisticRegression(C = 0.888809044392379, penalty = 'l2')  #bs, pos, polarity, pp \n",
    "ada_model = AdaBoostClassifier(learning_rate = 0.683683366733467, n_estimators = 134) #bs, pos pp pola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model.fit(X_train_pos, y_train)\n",
    "randomf_model.fit(X_train_pos, y_train)\n",
    "hist_model.fit(X_train_pos, y_train)\n",
    "logi_model.fit(X_train_pos, y_train)\n",
    "ada_model.fit(X_train_pos, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Irony data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/semeval_test3a_irony_onlysemeval.p', 'rb') as handle:\n",
    "    semeval = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semeval_pos = np.concatenate([semeval['pos'], semeval['bert_embed']], axis = 1)\n",
    "semeval_pp_pos_pol = np.concatenate([semeval['emoji']['emoji'],np.expand_dims(semeval['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(semeval['emoji']['emoji_negative'], axis = 1), semeval['pos'],semeval['punc'],\n",
    "                         semeval['onom'], semeval['init'], semeval['bert_embed'], semeval['polarity']], axis = 1)\n",
    "semeval_pp_pos = np.concatenate([semeval['emoji']['emoji'],np.expand_dims(semeval['emoji']['emoji_positive'], axis = 1), \n",
    "                                 np.expand_dims(semeval['emoji']['emoji_negative'], axis = 1), semeval['pos'],semeval['punc'],\n",
    "                                 semeval['onom'], semeval['init'], semeval['bert_embed']], axis = 1)\n",
    "y_semeval = semeval['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_output = get_outpupt_bma(xgb_model, semeval_pos, y_semeval)\n",
    "hist_output = get_outpupt_bma(hist_model, semeval_pos, y_semeval)\n",
    "rf_output = get_outpupt_bma(randomf_model, semeval_pos, y_semeval)\n",
    "ada_output = get_outpupt_bma(ada_model, semeval_pos, y_semeval)\n",
    "logi_output = get_outpupt_bma(logi_model, semeval_pos, y_semeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_output.to_csv('../Code/BMA/results_semeval/input/prediction_file/xgb_labels_semeval.csv', index = False)\n",
    "hist_output.to_csv('../Code/BMA/results_semeval/input/prediction_file/hist_labels_semeval.csv', index = False)\n",
    "rf_output.to_csv('../Code/BMA/results_semeval/input/prediction_file/rf_labels_semeval.csv', index = False)\n",
    "ada_output.to_csv('../Code/BMA/results_semeval/input/prediction_file/ada_labels_semeval.csv', index = False)\n",
    "logi_output.to_csv('../Code/BMA/results_semeval/input/prediction_file/logi_labels_semeval.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(classification_report(randomf_model.predict(semeval_pos), y_semeval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(logi_model.predict(semeval_pos), y_semeval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
